{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib as jb\n",
    "import PIL\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.style.use('seaborn-dark')\n",
    "\n",
    "# declare paths to data\n",
    "TRAIN_PATH = 'data/train'\n",
    "VALID_PATH = 'data/validation'\n",
    "TEST_PATH = 'data/test'\n",
    "CLASSES = ['Damselflies', 'Dragonflies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data/train\": {\n",
      "        \"Damselflies\": 6100,\n",
      "        \"Dragonflies\": 6628\n",
      "    },\n",
      "    \"data/validation\": {\n",
      "        \"Damselflies\": 670,\n",
      "        \"Dragonflies\": 736\n",
      "    },\n",
      "    \"data/test\": {\n",
      "        \"Damselflies\": 1692,\n",
      "        \"Dragonflies\": 1840\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data_summary = {}\n",
    "for directory in [TRAIN_PATH, VALID_PATH, TEST_PATH]:\n",
    "    data_summary[directory] = {}\n",
    "    for class_name in CLASSES:\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        data_summary[directory][class_name] = len(os.listdir(class_path))\n",
    "        \n",
    "print(json.dumps(data_summary, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation Pipeline\n",
    "\n",
    "* #### Training Data\n",
    "\n",
    "    1. Shuffle\n",
    "    1. Resize image\n",
    "    1. Grayscale image\n",
    "    1. Noramalize pixel values\n",
    "    1. Horizontal image flip\n",
    "    1. Vertical image flip\n",
    "    1. Rotate image\n",
    "    1. Adjusted image brightness\n",
    "       \n",
    "    \n",
    "* #### Validation & Testing data\n",
    "\n",
    "    1. Noramalize pixel values\n",
    "    2. Grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare image augmentation related hyperparameters\n",
    "TARGET_SIZE = (256, 256)\n",
    "RESCALE = 1.0 / 255\n",
    "COLOR_MODE = 'grayscale'\n",
    "BATCH_SIZE = 16\n",
    "ROTATION = 25\n",
    "BRIGHTNESS = [0.4, 1.0]\n",
    "\n",
    "# declare flow related hyper parameters \n",
    "EPOCHS = 29\n",
    "CLASS_MODE = 'categorical'\n",
    "CHECKPOINT = \"checkpoints/weight1s.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12728 images belonging to 2 classes.\n",
      "Found 1406 images belonging to 2 classes.\n",
      "Epoch 1/29\n",
      "796/796 [==============================] - 204s 257ms/step - loss: 0.6017 - accuracy: 0.6516 - val_loss: 0.1663 - val_accuracy: 0.7582\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75818, saving model to checkpoints/weight1s.hdf5\n",
      "Epoch 2/29\n",
      "  2/796 [..............................] - ETA: 48s - loss: 0.4826 - accuracy: 0.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GILOR\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 197s 247ms/step - loss: 0.4749 - accuracy: 0.7693 - val_loss: 0.1571 - val_accuracy: 0.8307\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.75818 to 0.83073, saving model to checkpoints/weight1s.hdf5\n",
      "Epoch 3/29\n",
      "796/796 [==============================] - 197s 247ms/step - loss: 0.4110 - accuracy: 0.8054 - val_loss: 0.2238 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.83073 to 0.84566, saving model to checkpoints/weight1s.hdf5\n",
      "Epoch 4/29\n",
      "796/796 [==============================] - 193s 242ms/step - loss: 0.3839 - accuracy: 0.8192 - val_loss: 0.2158 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.84566 to 0.86202, saving model to checkpoints/weight1s.hdf5\n",
      "Epoch 5/29\n",
      "796/796 [==============================] - 192s 241ms/step - loss: 0.3615 - accuracy: 0.8319 - val_loss: 0.3556 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.86202\n",
      "Epoch 6/29\n",
      "796/796 [==============================] - 192s 241ms/step - loss: 0.3481 - accuracy: 0.8371 - val_loss: 0.1359 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.86202 to 0.87198, saving model to checkpoints/weight1s.hdf5\n",
      "Epoch 7/29\n",
      "796/796 [==============================] - 193s 242ms/step - loss: 0.3342 - accuracy: 0.8479 - val_loss: 0.4509 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.87198 to 0.87269, saving model to checkpoints/weight1s.hdf5\n",
      "Epoch 8/29\n",
      "796/796 [==============================] - 197s 247ms/step - loss: 0.3164 - accuracy: 0.8559 - val_loss: 0.2863 - val_accuracy: 0.8784\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.87269 to 0.87838, saving model to checkpoints/weight1s.hdf5\n",
      "Epoch 9/29\n",
      "796/796 [==============================] - 192s 242ms/step - loss: 0.3063 - accuracy: 0.8635 - val_loss: 0.5396 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.87838\n",
      "Epoch 10/29\n",
      "796/796 [==============================] - 192s 241ms/step - loss: 0.2931 - accuracy: 0.8684 - val_loss: 0.2325 - val_accuracy: 0.8926\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.87838 to 0.89260, saving model to checkpoints/weight1s.hdf5\n",
      "Epoch 11/29\n",
      "580/796 [====================>.........] - ETA: 50s - loss: 0.2832 - accuracy: 0.8755"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Input, UpSampling2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# randomly flip, and rotate images, adjust brightish, and normalize pixel values\n",
    "trainGenerator = ImageDataGenerator(rescale=RESCALE, \n",
    "                                    horizontal_flip=True,  \n",
    "                                    vertical_flip=True,\n",
    "                                    rotation_range=ROTATION,\n",
    "                                    brightness_range=BRIGHTNESS)  \n",
    "\n",
    "# only scale the pixel values validation images\n",
    "validatioinGenerator = ImageDataGenerator(rescale=RESCALE)\n",
    "\n",
    "# only scale the pixel values test images\n",
    "testGenerator = ImageDataGenerator(rescale=RESCALE)\n",
    "\n",
    "# instanciate train flow\n",
    "trainFlow = trainGenerator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size = TARGET_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    color_mode = COLOR_MODE,\n",
    "    class_mode = CLASS_MODE,\n",
    "    shuffle=True\n",
    ") \n",
    "\n",
    "# instanciate validation flow\n",
    "validationFlow = validatioinGenerator.flow_from_directory(\n",
    "    VALID_PATH,\n",
    "    target_size = TARGET_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    color_mode = COLOR_MODE,\n",
    "    class_mode= CLASS_MODE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "## Define Model Architecture\n",
    "# I tried to create a light-weight version of the VGG16.\n",
    "# Instead of two convolution layers before MaxPooling, \n",
    "# I limited it to one Convolution layer\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(256 , 256, 1)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu' ),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(.3),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# trial and error, lowering learning rate gets better results\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.0005)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# create model checkpoint in case of overfitting\n",
    "checkpoints = ModelCheckpoint(CHECKPOINT, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    trainFlow,\n",
    "    validation_data=validationFlow, \n",
    "    callbacks=[checkpoints],\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "model.save('Linnaeus_bot1')\n",
    "jb.dump(history, 'training_history1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "\n",
    "model = load_model('Linnaeus_bot1')\n",
    "model.load_weights(CHECKPOINT)\n",
    "history = jp.load('training_history.pkl')\n",
    "\n",
    "# only scale the pixel values test images\n",
    "testGenerator = ImageDataGenerator(rescale=RESCALE)\n",
    "\n",
    "testFlow = testGenerator.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size = TARGET_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    color_mode = COLOR_MODE,\n",
    "    class_mode= CLASS_MODE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "# custom tensorflow optimizer with keras model requires compiling the model again\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.0005)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "loss, acc = model.evaluate(testFlow)\n",
    "print(f'Test accuracy\" {acc}')\n",
    "print(f'Test loss\" {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the images and predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
