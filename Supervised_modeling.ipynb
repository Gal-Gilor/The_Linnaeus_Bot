{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Input, UpSampling2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare paths to data\n",
    "TRAIN_PATH = 'data/train'\n",
    "VALID_PATH = 'data/validation'\n",
    "TEST_PATH = 'data/test'\n",
    "\n",
    "# declare image augmentation related hyperparameters\n",
    "TARGET_SIZE = (256, 256)\n",
    "RESCALE = 1.0 / 255\n",
    "COLOR_MODE = 'grayscale'\n",
    "BATCH_SIZE = 16\n",
    "ROTATION = 25\n",
    "BRIGHTNESS = [0.4, 1.0]\n",
    "\n",
    "# declare flow related hyper parameters \n",
    "EPOCHS = 30\n",
    "CLASSES = ['Damselflies', 'Dragonflies']\n",
    "CLASS_MODE = 'categorical'\n",
    "CHECKPOINT = \"../checkpoints/weights.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation Pipeline\n",
    "\n",
    "* #### Training Data\n",
    "\n",
    "    1. Noramalize pixel values\n",
    "    2. Horizontal image flip\n",
    "    3. Vertical image flip\n",
    "    4. Rotate image\n",
    "    5. Adjusted image brightness\n",
    "    6. Grayscale images\n",
    "    7. Shuffle\n",
    "    \n",
    "    \n",
    "* #### Validation & Testing data\n",
    "\n",
    "    1. Noramalize pixel values\n",
    "    2. Grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly flip, and rotate images, adjust brightish, and normalize pixel values\n",
    "trainGenerator = ImageDataGenerator(rescale=RESCALE, \n",
    "                                    horizontal_flip=True,  \n",
    "                                    vertical_flip=True,\n",
    "                                    rotation_range=ROTATION,\n",
    "                                    brightness_range=BRIGHTNESS)  \n",
    "\n",
    "# only scale the pixel values validation images\n",
    "validatioinGenerator = ImageDataGenerator(rescale=RESCALE)\n",
    "\n",
    "# only scale the pixel values test images\n",
    "testGenerator = ImageDataGenerator(rescale=RESCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciate train flow\n",
    "trainFlow = trainGenerator.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size = TARGET_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    classes = CLASSES,\n",
    "    color_mode = COLOR_MODE,\n",
    "    class_mode = CLASS_MODE,\n",
    "    shuffle=True\n",
    ") \n",
    "\n",
    "# instanciate validation flow\n",
    "validationFlow = validatioinGenerator.flow_from_directory(\n",
    "    VALID_PATH,\n",
    "    target_size = TARGET_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    #classes = CLASSES,\n",
    "    color_mode = COLOR_MODE,\n",
    "    class_mode= CLASS_MODE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Architecture\n",
    "\n",
    "\n",
    "I tried to create a light-weight version of the VGG16.\n",
    "\n",
    "Instead of two convolution layers before MaxPooling, \n",
    "I limited it to one Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(256 , 256, 1)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu' ),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(.3),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(.3),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model checkpoint in case of overfitting\n",
    "checkpoints = ModelCheckpoint(CHECKPOINT, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    trainFlow,\n",
    "    validation_data=validationFlow, \n",
    "    callbacks=[checkpoints],\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
