{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib as jb\n",
    "import helper_functions as hlf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 18407\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed dragonfly images\n",
    "trainpath = r'D:\\Linnaeus_models\\dragon\\train\\dragon_train.npy'\n",
    "testpath = r'D:\\Linnaeus_models\\dragon\\test\\dragon_test.npy'\n",
    "dragons = np.concatenate((np.load(trainpath), np.load(testpath)), axis=0)\n",
    "print(f'Number of images: {len(dragons)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Image Denoising with CNN\n",
    "   * Test image denoising abilities on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into training set and validation set and reshape to fit the NN\n",
    "x_train = dragons[0:16000] \n",
    "x_val = dragons[16000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_val = np.expand_dims(x_val, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = hlf.create_unsupervised_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_history = model.fit(x_train, x_train, epochs=8, batch_size=100, \n",
    "                          validation_data=(x_val, x_val))\n",
    "# save model\n",
    "model_path =  r'D:\\Linnaeus_models\\dragon_reconstruction_v1.pkl'\n",
    "jb.dump(loaded_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload unsupervised model to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "loaded_model = jb.load(r'D:\\Linnaeus_models\\dragon_reconstruction_v4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 2407 samples\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - ETA: 1:00:10 - loss: 0.00 - ETA: 55:32 - loss: 0.0087 - ETA: 53:10 - loss: 0.00 - ETA: 51:36 - loss: 0.00 - ETA: 51:05 - loss: 0.00 - ETA: 50:50 - loss: 0.00 - ETA: 50:09 - loss: 0.00 - ETA: 49:34 - loss: 0.00 - ETA: 49:02 - loss: 0.00 - ETA: 48:33 - loss: 0.00 - ETA: 48:08 - loss: 0.00 - ETA: 47:48 - loss: 0.00 - ETA: 47:23 - loss: 0.00 - ETA: 47:22 - loss: 0.00 - ETA: 47:36 - loss: 0.00 - ETA: 48:01 - loss: 0.00 - ETA: 48:21 - loss: 0.00 - ETA: 48:12 - loss: 0.00 - ETA: 47:42 - loss: 0.00 - ETA: 47:15 - loss: 0.00 - ETA: 46:46 - loss: 0.00 - ETA: 46:18 - loss: 0.00 - ETA: 45:52 - loss: 0.00 - ETA: 45:25 - loss: 0.00 - ETA: 44:59 - loss: 0.00 - ETA: 44:32 - loss: 0.00 - ETA: 44:07 - loss: 0.00 - ETA: 43:42 - loss: 0.00 - ETA: 43:17 - loss: 0.00 - ETA: 42:58 - loss: 0.00 - ETA: 42:39 - loss: 0.00 - ETA: 42:17 - loss: 0.00 - ETA: 41:56 - loss: 0.00 - ETA: 41:34 - loss: 0.00 - ETA: 41:14 - loss: 0.00 - ETA: 40:57 - loss: 0.00 - ETA: 40:38 - loss: 0.00 - ETA: 40:18 - loss: 0.00 - ETA: 39:59 - loss: 0.00 - ETA: 39:38 - loss: 0.00 - ETA: 39:18 - loss: 0.00 - ETA: 38:57 - loss: 0.00 - ETA: 38:38 - loss: 0.00 - ETA: 38:18 - loss: 0.00 - ETA: 37:57 - loss: 0.00 - ETA: 37:36 - loss: 0.00 - ETA: 37:15 - loss: 0.00 - ETA: 36:55 - loss: 0.00 - ETA: 36:34 - loss: 0.00 - ETA: 36:14 - loss: 0.00 - ETA: 35:56 - loss: 0.00 - ETA: 35:36 - loss: 0.00 - ETA: 35:16 - loss: 0.00 - ETA: 34:57 - loss: 0.00 - ETA: 34:37 - loss: 0.00 - ETA: 34:18 - loss: 0.00 - ETA: 33:58 - loss: 0.00 - ETA: 33:38 - loss: 0.00 - ETA: 33:17 - loss: 0.00 - ETA: 32:57 - loss: 0.00 - ETA: 32:37 - loss: 0.00 - ETA: 32:17 - loss: 0.00 - ETA: 31:57 - loss: 0.00 - ETA: 31:37 - loss: 0.00 - ETA: 31:16 - loss: 0.00 - ETA: 30:58 - loss: 0.00 - ETA: 30:38 - loss: 0.00 - ETA: 30:18 - loss: 0.00 - ETA: 29:56 - loss: 0.00 - ETA: 29:34 - loss: 0.00 - ETA: 29:11 - loss: 0.00 - ETA: 28:49 - loss: 0.00 - ETA: 28:27 - loss: 0.00 - ETA: 28:05 - loss: 0.00 - ETA: 27:43 - loss: 0.00 - ETA: 27:22 - loss: 0.00 - ETA: 27:00 - loss: 0.00 - ETA: 26:38 - loss: 0.00 - ETA: 26:18 - loss: 0.00 - ETA: 25:59 - loss: 0.00 - ETA: 25:39 - loss: 0.00 - ETA: 25:20 - loss: 0.00 - ETA: 25:02 - loss: 0.00 - ETA: 24:42 - loss: 0.00 - ETA: 24:23 - loss: 0.00 - ETA: 24:04 - loss: 0.00 - ETA: 23:44 - loss: 0.00 - ETA: 23:25 - loss: 0.00 - ETA: 23:05 - loss: 0.00 - ETA: 22:46 - loss: 0.00 - ETA: 22:26 - loss: 0.00 - ETA: 22:06 - loss: 0.00 - ETA: 21:47 - loss: 0.00 - ETA: 21:28 - loss: 0.00 - ETA: 21:08 - loss: 0.00 - ETA: 20:48 - loss: 0.00 - ETA: 20:28 - loss: 0.00 - ETA: 20:09 - loss: 0.00 - ETA: 19:49 - loss: 0.00 - ETA: 19:29 - loss: 0.00 - ETA: 19:08 - loss: 0.00 - ETA: 18:48 - loss: 0.00 - ETA: 18:27 - loss: 0.00 - ETA: 18:07 - loss: 0.00 - ETA: 17:47 - loss: 0.00 - ETA: 17:27 - loss: 0.00 - ETA: 17:07 - loss: 0.00 - ETA: 16:47 - loss: 0.00 - ETA: 16:27 - loss: 0.00 - ETA: 16:08 - loss: 0.00 - ETA: 15:47 - loss: 0.00 - ETA: 15:28 - loss: 0.00 - ETA: 15:07 - loss: 0.00 - ETA: 14:48 - loss: 0.00 - ETA: 14:28 - loss: 0.00 - ETA: 14:09 - loss: 0.00 - ETA: 13:50 - loss: 0.00 - ETA: 13:30 - loss: 0.00 - ETA: 13:11 - loss: 0.00 - ETA: 12:51 - loss: 0.00 - ETA: 12:31 - loss: 0.00 - ETA: 12:11 - loss: 0.00 - ETA: 11:52 - loss: 0.00 - ETA: 11:32 - loss: 0.00 - ETA: 11:12 - loss: 0.00 - ETA: 10:53 - loss: 0.00 - ETA: 10:33 - loss: 0.00 - ETA: 10:14 - loss: 0.00 - ETA: 9:54 - loss: 0.0080 - ETA: 9:35 - loss: 0.008 - ETA: 9:15 - loss: 0.008 - ETA: 8:56 - loss: 0.008 - ETA: 8:37 - loss: 0.008 - ETA: 8:18 - loss: 0.008 - ETA: 7:59 - loss: 0.008 - ETA: 7:40 - loss: 0.008 - ETA: 7:21 - loss: 0.008 - ETA: 7:03 - loss: 0.007 - ETA: 6:44 - loss: 0.008 - ETA: 6:26 - loss: 0.008 - ETA: 6:07 - loss: 0.007 - ETA: 5:48 - loss: 0.007 - ETA: 5:28 - loss: 0.007 - ETA: 5:09 - loss: 0.007 - ETA: 4:51 - loss: 0.007 - ETA: 4:32 - loss: 0.007 - ETA: 4:13 - loss: 0.007 - ETA: 3:54 - loss: 0.007 - ETA: 3:35 - loss: 0.007 - ETA: 3:15 - loss: 0.007 - ETA: 2:56 - loss: 0.007 - ETA: 2:37 - loss: 0.008 - ETA: 2:17 - loss: 0.008 - ETA: 1:58 - loss: 0.007 - ETA: 1:38 - loss: 0.008 - ETA: 1:18 - loss: 0.007 - ETA: 59s - loss: 0.008 - ETA: 39s - loss: 0.00 - ETA: 19s - loss: 0.00 - 3267s 204ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - ETA: 1:03:27 - loss: 0.00 - ETA: 56:01 - loss: 0.0084 - ETA: 56:19 - loss: 0.00 - ETA: 55:08 - loss: 0.00 - ETA: 54:14 - loss: 0.00 - ETA: 53:31 - loss: 0.00 - ETA: 53:19 - loss: 0.00 - ETA: 52:46 - loss: 0.00 - ETA: 52:14 - loss: 0.00 - ETA: 51:51 - loss: 0.00 - ETA: 51:31 - loss: 0.00 - ETA: 51:08 - loss: 0.00 - ETA: 50:35 - loss: 0.00 - ETA: 49:44 - loss: 0.00 - ETA: 49:00 - loss: 0.00 - ETA: 48:14 - loss: 0.00 - ETA: 47:32 - loss: 0.00 - ETA: 46:56 - loss: 0.00 - ETA: 46:33 - loss: 0.00 - ETA: 46:05 - loss: 0.00 - ETA: 45:37 - loss: 0.00 - ETA: 45:13 - loss: 0.00 - ETA: 44:53 - loss: 0.00 - ETA: 44:31 - loss: 0.00 - ETA: 44:06 - loss: 0.00 - ETA: 43:43 - loss: 0.00 - ETA: 43:22 - loss: 0.00 - ETA: 42:57 - loss: 0.00 - ETA: 42:31 - loss: 0.00 - ETA: 42:04 - loss: 0.00 - ETA: 41:42 - loss: 0.00 - ETA: 41:22 - loss: 0.00 - ETA: 41:01 - loss: 0.00 - ETA: 40:36 - loss: 0.00 - ETA: 40:17 - loss: 0.00 - ETA: 39:55 - loss: 0.00 - ETA: 39:33 - loss: 0.00 - ETA: 39:11 - loss: 0.00 - ETA: 38:55 - loss: 0.00 - ETA: 38:34 - loss: 0.00 - ETA: 38:13 - loss: 0.00 - ETA: 37:51 - loss: 0.00 - ETA: 37:30 - loss: 0.00 - ETA: 37:07 - loss: 0.00 - ETA: 36:44 - loss: 0.00 - ETA: 36:22 - loss: 0.00 - ETA: 36:00 - loss: 0.00 - ETA: 35:39 - loss: 0.00 - ETA: 35:17 - loss: 0.00 - ETA: 34:55 - loss: 0.00 - ETA: 34:34 - loss: 0.00 - ETA: 34:13 - loss: 0.00 - ETA: 33:52 - loss: 0.00 - ETA: 33:31 - loss: 0.00 - ETA: 33:09 - loss: 0.00 - ETA: 32:50 - loss: 0.00 - ETA: 32:29 - loss: 0.00 - ETA: 32:09 - loss: 0.00 - ETA: 31:49 - loss: 0.00 - ETA: 31:28 - loss: 0.00 - ETA: 31:08 - loss: 0.00 - ETA: 30:49 - loss: 0.00 - ETA: 30:28 - loss: 0.00 - ETA: 30:09 - loss: 0.00 - ETA: 29:52 - loss: 0.00 - ETA: 29:33 - loss: 0.00 - ETA: 29:15 - loss: 0.00 - ETA: 28:57 - loss: 0.00 - ETA: 28:37 - loss: 0.00 - ETA: 28:17 - loss: 0.00 - ETA: 27:57 - loss: 0.00 - ETA: 27:38 - loss: 0.00 - ETA: 27:18 - loss: 0.00 - ETA: 26:58 - loss: 0.00 - ETA: 26:38 - loss: 0.00 - ETA: 26:19 - loss: 0.00 - ETA: 25:59 - loss: 0.00 - ETA: 25:39 - loss: 0.00 - ETA: 25:19 - loss: 0.00 - ETA: 24:59 - loss: 0.00 - ETA: 24:39 - loss: 0.00 - ETA: 24:19 - loss: 0.00 - ETA: 24:00 - loss: 0.00 - ETA: 23:40 - loss: 0.00 - ETA: 23:23 - loss: 0.00 - ETA: 23:04 - loss: 0.00 - ETA: 22:46 - loss: 0.00 - ETA: 22:29 - loss: 0.00 - ETA: 22:13 - loss: 0.00 - ETA: 21:57 - loss: 0.00 - ETA: 21:38 - loss: 0.00 - ETA: 21:20 - loss: 0.00 - ETA: 21:02 - loss: 0.00 - ETA: 20:44 - loss: 0.00 - ETA: 20:26 - loss: 0.00 - ETA: 20:07 - loss: 0.00 - ETA: 19:49 - loss: 0.00 - ETA: 19:30 - loss: 0.00 - ETA: 19:13 - loss: 0.00 - ETA: 18:56 - loss: 0.00 - ETA: 18:36 - loss: 0.00 - ETA: 18:17 - loss: 0.00 - ETA: 17:59 - loss: 0.00 - ETA: 17:40 - loss: 0.00 - ETA: 17:21 - loss: 0.00 - ETA: 17:03 - loss: 0.00 - ETA: 16:44 - loss: 0.00 - ETA: 16:25 - loss: 0.00 - ETA: 16:06 - loss: 0.00 - ETA: 15:47 - loss: 0.00 - ETA: 15:28 - loss: 0.00 - ETA: 15:09 - loss: 0.00 - ETA: 14:50 - loss: 0.00 - ETA: 14:31 - loss: 0.00 - ETA: 14:13 - loss: 0.00 - ETA: 13:54 - loss: 0.00 - ETA: 13:35 - loss: 0.00 - ETA: 13:16 - loss: 0.00 - ETA: 12:57 - loss: 0.00 - ETA: 12:38 - loss: 0.00 - ETA: 12:19 - loss: 0.00 - ETA: 12:00 - loss: 0.00 - ETA: 11:41 - loss: 0.00 - ETA: 11:23 - loss: 0.00 - ETA: 11:04 - loss: 0.00 - ETA: 10:45 - loss: 0.00 - ETA: 10:26 - loss: 0.00 - ETA: 10:07 - loss: 0.00 - ETA: 9:48 - loss: 0.0080 - ETA: 9:29 - loss: 0.008 - ETA: 9:10 - loss: 0.008 - ETA: 8:51 - loss: 0.008 - ETA: 8:32 - loss: 0.008 - ETA: 8:13 - loss: 0.008 - ETA: 7:54 - loss: 0.008 - ETA: 7:35 - loss: 0.008 - ETA: 7:16 - loss: 0.008 - ETA: 6:57 - loss: 0.008 - ETA: 6:38 - loss: 0.008 - ETA: 6:19 - loss: 0.008 - ETA: 6:00 - loss: 0.008 - ETA: 5:41 - loss: 0.008 - ETA: 5:22 - loss: 0.008 - ETA: 5:03 - loss: 0.008 - ETA: 4:44 - loss: 0.008 - ETA: 4:25 - loss: 0.008 - ETA: 4:06 - loss: 0.008 - ETA: 3:47 - loss: 0.008 - ETA: 3:28 - loss: 0.008 - ETA: 3:09 - loss: 0.008 - ETA: 2:50 - loss: 0.008 - ETA: 2:31 - loss: 0.008 - ETA: 2:12 - loss: 0.008 - ETA: 1:53 - loss: 0.008 - ETA: 1:34 - loss: 0.008 - ETA: 1:15 - loss: 0.008 - ETA: 56s - loss: 0.008 - ETA: 37s - loss: 0.00 - ETA: 18s - loss: 0.00 - 3147s 197ms/step - loss: 0.0080 - val_loss: 0.0075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['D:\\\\Linnaeus_models\\\\dragon_reconstruction_v4.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continue training the unsupervised model\n",
    "train_history = loaded_model.fit(x_train, x_train, epochs=2, batch_size=100, \n",
    "                                 validation_data=(x_val, x_val))\n",
    "\n",
    "# save model and weights\n",
    "loaded_model.save_weights(r'D:\\Linnaeus_models\\dragon_reconstruction_v4_weights')\n",
    "model_path =  r'D:\\Linnaeus_models\\dragon_reconstruction_v4.pkl'\n",
    "jb.dump(loaded_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./test_images/val_images.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and save the images\n",
    "preds = loaded_model.predict(x_val)\n",
    "jb.dump(preds, './test_images/unsupervised_val_images.pkl')\n",
    "jb.dump(x_val, './test_images/val_images.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
