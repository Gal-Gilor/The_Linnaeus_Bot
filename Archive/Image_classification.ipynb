{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib as jb\n",
    "import helper_functions as hlf\n",
    "\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN\n",
    "   1. Load training images\n",
    "   2. Add labels\n",
    "   3. Create a validation set\n",
    "   4. Create model\n",
    "   5. Train model\n",
    "   6. Save model weights and train history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 0, 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images to train the clasifier\n",
    "damsel_train_path = r'D:\\Linnaeus_models\\damsel\\train\\damsel_train.npy'\n",
    "dragon_train_path = r'D:\\Linnaeus_models\\dragon\\train\\dragon_train.npy'\n",
    "training_data, labels = hlf.load_data(damsel_train_path, dragon_train_path, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GILOR\\.conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 254, 254, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 252, 252, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 122, 122, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 59, 59, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 57, 57, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 13,148,386\n",
      "Trainable params: 13,148,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create training/validation sets\n",
    "x_train, x_val, y_train, y_val, y_train_cat, y_val_cat = hlf.create_train_validation(training_data, labels)\n",
    "\n",
    "# create and compile keras seqeuntial model\n",
    "model = hlf.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_history = model.fit(x_train, y_train, epochs=10, batch_size=180,\n",
    "                          validation_data=(x_val, y_val)\n",
    "                         )\n",
    "# save weights and training history object                        \n",
    "model.save_weights('./model_weights/first2000')\n",
    "variable =  './train_history/first2000'\n",
    "jb.dump(train_history, variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear Cache\n",
    "  1. Load previous model weights\n",
    "  2. Load unseen images\n",
    "  3. Create a validation set\n",
    "  4. Retrain model\n",
    "  5. Save model weights and train history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset kernel, Load past model and retrain on the model on new images\n",
    "weights_path = './model_weights/'\n",
    "weights_name = 'fifth2000'\n",
    "pre_trained_model = hlf.create_model(weights_path, weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new images\n",
    "start, end = 10000, 12000\n",
    "\n",
    "damsel_train_path = r'D:\\Linnaeus_models\\damsel\\train\\damsel_train.npy'\n",
    "dragon_train_path = r'D:\\Linnaeus_models\\dragon\\train\\dragon_train.npy'\n",
    "\n",
    "training_data, labels = hlf.load_data(damsel_train_path, dragon_train_path, start, end)\n",
    "# create train/validation sets\n",
    "x_train, x_val, y_train, y_val, y_train_cat, y_val_cat = hlf.create_train_validation(training_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain the model with the new images\n",
    "train_history = pre_trained_model.fit(x_train, y_train_cat, epochs=10, batch_size=200,\n",
    "                                      validation_data=(x_val, y_val_cat)\n",
    "                                     )\n",
    "# save weights and train history object\n",
    "pre_trained_model.save_weights('./model_weights/sixth2000')\n",
    "history_path = './train_history/sixth2000'\n",
    "jb.dump(train_history, history_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - test how the model performs after retraining\n",
    "loss, acc = pre_trained_model.evaluate(x_val, to_categorical(y_val))\n",
    "print(f'Validation accuracy: {acc * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
